{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the code blocks, run the following commands to get the kernel prepared:\n",
    "```sh\n",
    "julia\n",
    "import Pkg\n",
    "Pkg.update()\n",
    "Pkg.precompile()\n",
    "\n",
    "using Pkg\n",
    "Pkg.build(\"IJulia\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "using HDF5\n",
    "using Serialization\n",
    "using DataFrames, Plots, Statistics\n",
    "using Plots.PlotMeasures \n",
    "using DataFramesMeta\n",
    "using Missings\n",
    "using ColorSchemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "safe_max (generic function with 1 method)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_data(v) = any(!ismissing, v)\n",
    "safe_mean(v) = has_data(v) ? mean(skipmissing(v)) : missing\n",
    "safe_std(v) = has_data(v) ? std(collect(skipmissing(v)); corrected=false) : missing\n",
    "safe_min(v)  = has_data(v) ? minimum(skipmissing(v)) : missing\n",
    "safe_max(v)  = has_data(v) ? maximum(skipmissing(v)) : missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rename_optimization (generic function with 1 method)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rename_regime(trial)\n",
    "    if trial == \"1(1.0) particles\"\n",
    "        return \"Extreme degeneracy\"\n",
    "    elseif trial == \"1(0.999) particles\"\n",
    "        return \"High degeneracy\"\n",
    "    elseif trial == \"1(0.99) particles\"\n",
    "        return \"Near-degeneracy(0.99)\"\n",
    "    elseif trial == \"50%(1.0) particles\"\n",
    "        return \"Balanced case\"\n",
    "    elseif trial == \"all(1.0) particles\"\n",
    "        return \"Uniform case\"\n",
    "    end\n",
    "    return trial\n",
    "end\n",
    "\n",
    "function rename_stats(metric)\n",
    "    if metric == \"waitall_ratio\"\n",
    "        return \"Waitall/Overall Time Ratio\"\n",
    "    elseif metric == \"overall\"\n",
    "        return \"Overall Time (s)\"\n",
    "    elseif metric == \"copy_states\"\n",
    "        return \"Copy States Time (s)\"\n",
    "    elseif metric == \"waitall_phase\"\n",
    "        return \"Waitall Time (s)\"\n",
    "    elseif metric == \"optimize_resample\"\n",
    "        return \"Optimise Resample (s)\"\n",
    "    elseif metric == \"resample_ratio\"\n",
    "        return \"Overhead Time Ratio\"\n",
    "    else\n",
    "        return metric\n",
    "    end\n",
    "end\n",
    "\n",
    "function rename_optimization(optimization)\n",
    "    if optimization == \"original\"\n",
    "        return \"Baseline\"\n",
    "    elseif optimization == \"only_optimize_resampling\"\n",
    "        return \"Optimise Resampling Only\"\n",
    "    elseif optimization == \"only_dedup\"\n",
    "        return \"Deduplication Only\"\n",
    "    elseif optimization == \"dedup_threading\"\n",
    "        return \"Deduplication + Threading\"\n",
    "    elseif optimization == \"dedup_threading_optimize_resampling\"\n",
    "        return \"Full Optimisation\"\n",
    "    else\n",
    "        return optimization\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timer_dict_to_df (generic function with 3 methods)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function timer_dict_to_df(timer_dict, optimization, flatten=false)\n",
    "    rows = []\n",
    "\n",
    "    for (trial, ranks) in timer_dict\n",
    "        k, total_rank, nprt_per_rank, n_float_per_particle, perm, p = split(trial, \":\")\n",
    "        k = k == \"half\" ? \"50%\" : k\n",
    "        trial_name = \"$k($p) particles\"\n",
    "        for (rank, timers) in ranks\n",
    "            function format_row(op, metric, value)\n",
    "                return (\n",
    "                    optimization = optimization,\n",
    "                    trial  = String(trial_name),\n",
    "                    perm = String(perm),\n",
    "                    total_rank = parse(Int, total_rank),\n",
    "                    particle_size = n_float_per_particle,\n",
    "                    nprt_per_rank = nprt_per_rank,\n",
    "                    rank   = string(rank),\n",
    "                    op     = String(op),\n",
    "                    metric = String(metric),\n",
    "                    value  = value,\n",
    "                )\n",
    "            end\n",
    "            function recursive_push(inner_timers)\n",
    "                for (op, metrics) in inner_timers\n",
    "                    if op == \"receive loop\" && flatten\n",
    "                        for (inner_op, inner_metrics) in metrics[\"inner_timers\"]\n",
    "                            for (metric, value) in inner_metrics\n",
    "                                push!(rows, format_row(inner_op, metric, value))\n",
    "                            end\n",
    "                        end\n",
    "                    else\n",
    "                        push!(rows, format_row(op, \"time_s\", metrics[\"time_ns\"] / 1e9))\n",
    "                        push!(rows, format_row(op, \"n_calls\", metrics[\"n_calls\"]))\n",
    "                        recursive_push(metrics[\"inner_timers\"])\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            push!(rows, format_row(\"overall\", \"time_s\", timers[\"time_ns\"] / 1e9))\n",
    "            push!(rows, format_row(\"overall\", \"n_calls\", timers[\"n_calls\"]))\n",
    "            recursive_push(timers[\"inner_timers\"])\n",
    "        end\n",
    "    end\n",
    "    return DataFrame(rows)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_from_h5 (generic function with 1 method)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function df_from_h5(root_dir, category)\n",
    "    optimization = split(category, \"/\")[end]\n",
    "\n",
    "    root = dirname(@__FILE__)\n",
    "    h5path(rank) = joinpath(root, \"../$(root_dir)/$(category)/\", \"all_timers_$(rank).h5\") \n",
    "    all_timer_dfs = DataFrame()\n",
    "    for rank in [2, 4, 8, 16, 32]\n",
    "        blob = h5open(h5path(rank)) do f\n",
    "            read(f, \"all_timers\")\n",
    "        end\n",
    "\n",
    "        # Deserialize back into Dict{String,Dict{Int,Dict{String,Any}}}\n",
    "        merged_timers = deserialize(IOBuffer(blob))\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        timer_df = timer_dict_to_df(merged_timers, optimization)\n",
    "        \n",
    "        # Concat to all_timer_dfs\n",
    "        all_timer_dfs = vcat(all_timer_dfs, timer_df)\n",
    "    end\n",
    "\n",
    "    wide = unstack(\n",
    "    all_timer_dfs,\n",
    "    [:optimization, :trial, :perm, :total_rank, :nprt_per_rank, :particle_size, :rank, :op],\n",
    "    :metric,\n",
    "    :value\n",
    "    )\n",
    "    # Sort by perm and trial\n",
    "    wide = sort!(wide, [:perm, :trial])\n",
    "\n",
    "    rand_df = wide[wide.perm .== \"randperm\", :]\n",
    "    return rand_df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "widen_ops (generic function with 1 method)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function widen_ops(df::DataFrame)\n",
    "    rename!(df, Symbol.(names(df)))\n",
    "\n",
    "    keys   = [:optimization, :trial, :perm, :total_rank, :nprt_per_rank, :particle_size, :rank]\n",
    "    wanted = [\"overall\",\"waitall\",\"broadcast\",\"copy states\",\"write from buffer\",\"write to buffer\", \"waitall phase\", \"buffer write-back\",\n",
    "              \"receive loop\",\"send loop\",\"irecv\",\"remote duplicates copy\", \"optimize resample\", \"local copy\", \"remote receive\", \"send plan\", \"receive plan\", \"local replication\", \"local replication\", \"remote replication\"]\n",
    "\n",
    "    df2 = subset(df, :op => ByRow(in(wanted)))\n",
    "\n",
    "    transform!(df2, :n_calls => ByRow(x -> x == 0 ? missing : x) => :n_calls)\n",
    "\n",
    "    g = groupby(df2, vcat(keys, [:op]))\n",
    "    avg = combine(g,\n",
    "        [:time_s, :n_calls] => ((t, c) -> sum(t) / sum(c) ) => :time_s_per_call\n",
    "    )\n",
    "\n",
    "    wide = unstack(avg, keys, :op, :time_s_per_call; combine=first)\n",
    "    rename!(wide, Symbol.(replace.(string.(names(wide)), r\"[ -]\" => \"_\")))\n",
    "    return wide\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stats (generic function with 1 method)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function stats(df_stats)\n",
    "    df_stats = @chain df_stats[df_stats.total_rank .> 1, :] begin\n",
    "        @transform(\n",
    "            :waitall_ratio = :waitall_phase ./ :overall,\n",
    "            :localcopy_ratio = :local_replication ./ :overall,\n",
    "            :remotedup_ratio = :remote_replication ./ :overall,\n",
    "            :writefrombuf_ratio = :buffer_write_back ./ :overall,\n",
    "            :resample_ratio = :optimize_resample ./ :overall,\n",
    "        )\n",
    "    end\n",
    "    return df_stats\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "render_stats (generic function with 3 methods)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function render_stats(df, stats_to_plot=[\"overall\", \"copy_states\", \"waitall_phase\", \"waitall_ratio\"])\n",
    "    # Configuration for plots\n",
    "    trials = [\"1(1.0) particles\", \"1(0.99) particles\", \"50%(1.0) particles\", \"all(1.0) particles\"]\n",
    "    optimizations = unique(df.optimization)\n",
    "    ntrials = length(trials)\n",
    "    nstats = length(stats_to_plot)\n",
    "    n_opts = length(optimizations)\n",
    "\n",
    "    # --- Create the individual plots for the grid ---\n",
    "    axes = []\n",
    "    for (i, trial) in enumerate(trials)\n",
    "        for (j, stat) in enumerate(stats_to_plot)\n",
    "            # Create a new plot object for this subplot\n",
    "            p = plot(legend=false, palette=:auto, bottom_margin=10mm)\n",
    "            \n",
    "            # --- Set conditional labels and titles ---\n",
    "            if i == 1\n",
    "                plot!(p, title = rename_stats(stat), top_margin = 10mm)\n",
    "            end\n",
    "            if j == 1\n",
    "                plot!(p, ylabel = rename_regime(trial), left_margin = 20mm)\n",
    "            end\n",
    "            if i == ntrials\n",
    "                plot!(p, xlabel = \"Total Rank\", bottom_margin = 10mm)\n",
    "            end\n",
    "\n",
    "            df_filtered = df[df.trial .== trial, :]\n",
    "            \n",
    "            # --- Add each optimization as a series to the plot ---\n",
    "            for optimization in optimizations\n",
    "                sub = select(df_filtered, :optimization, :total_rank, :rank, stat => :value)\n",
    "                subrk = sub[sub.optimization .== optimization, :]\n",
    "                isempty(subrk) && continue\n",
    "\n",
    "                # Determine if log scale should be used\n",
    "                use_log = stat in [\"overall\", \"copy_states\", \"waitall_phase\"]\n",
    "\n",
    "                # Group and calculate statistics.\n",
    "                g = if use_log\n",
    "                    # Add a small epsilon to avoid log(0) issues\n",
    "                    subrk_log = @transform(subrk, :log_value = log10.(:value .+ 1e-12))\n",
    "                    \n",
    "                    # Calculate stats in both linear (for mean) and log (for std) space\n",
    "                    g_linear = combine(groupby(subrk, :total_rank), :value => safe_mean => :mean)\n",
    "                    g_log = combine(groupby(subrk_log, :total_rank), :log_value => safe_std  => :std_log)\n",
    "                    \n",
    "                    # Join them together and return\n",
    "                    leftjoin(g_linear, g_log, on = :total_rank)\n",
    "                else\n",
    "                    combine(groupby(subrk, :total_rank),\n",
    "                            :value => safe_mean => :mean,\n",
    "                            :value => safe_std  => :std)\n",
    "                end\n",
    "\n",
    "                # Filter out rows with missing data and sort\n",
    "                filter!(row -> all(!ismissing, values(row)), g)\n",
    "                sort!(g, :total_rank)\n",
    "                isempty(g) && continue\n",
    "                \n",
    "                # Prepare plot variables (mean and ribbon) based on the scale\n",
    "                local plot_mean, ribbon_val\n",
    "                if use_log\n",
    "                    plot!(p, yaxis=:log)\n",
    "                    # Use the arithmetic mean for the central line\n",
    "                    plot_mean = g.mean\n",
    "                    \n",
    "                    # Calculate the geometric standard deviation as a multiplicative factor\n",
    "                    gstd = 10 .^ g.std_log\n",
    "                    \n",
    "                    # Define ribbon bounds multiplicatively around the arithmetic mean\n",
    "                    lower_bound = plot_mean ./ gstd\n",
    "                    upper_bound = plot_mean .* gstd\n",
    "                    \n",
    "                    # The ribbon is the distance from the central line\n",
    "                    ribbon_val = (plot_mean .- lower_bound, upper_bound .- plot_mean)\n",
    "                else\n",
    "                    plot_mean = g.mean\n",
    "                    ribbon_val = g.std\n",
    "                end\n",
    "\n",
    "                plot!(p, string.(g.total_rank), plot_mean,\n",
    "                      ribbon = ribbon_val, seriestype = :path,\n",
    "                      markersize = 4, linewidth = 1.5)\n",
    "            end\n",
    "            push!(axes, p)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # --- Create the global legend ---\n",
    "    legend_labels = permutedims([rename_optimization(opt) for opt in optimizations])\n",
    "    legend_plot = plot(\n",
    "        (1:n_opts)', # Dummy data for legend entries\n",
    "        legend = :top,\n",
    "        legend_columns = -1, # Force a single horizontal row\n",
    "        labels = legend_labels,\n",
    "        framestyle = :none,\n",
    "        palette = :auto,\n",
    "        size = (1,1)\n",
    "    )\n",
    "\n",
    "    # --- Combine legend and plots into the final figure ---\n",
    "    final_fig = plot(\n",
    "        legend_plot,\n",
    "        axes...,\n",
    "        layout = @layout([A{0.05h}; grid(ntrials, nstats)]),\n",
    "        size = (400 * nstats, 300 * ntrials)\n",
    "    )\n",
    "\n",
    "    return final_fig\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"test/output29\"\n",
    "original_100k_df = df_from_h5(root_dir, \"original\")\n",
    "dedup_100k_df = df_from_h5(root_dir, \"only_dedup\")\n",
    "dedup_threads_100k_df = df_from_h5(root_dir, \"dedup_threading\")\n",
    "# op_100k_df = df_from_h5(root_dir, \"only_optimize_resampling\")\n",
    "dtop_100k_df = df_from_h5(root_dir, \"dedup_threading_optimize_resampling\")\n",
    "\n",
    "union_df = vcat(original_100k_df, dedup_100k_df, dedup_threads_100k_df, dtop_100k_df)\n",
    "union_df = widen_ops(union_df)\n",
    "union_df = stats(union_df)\n",
    "render_stats(union_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
