{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the code blocks, run the following commands to get the kernel prepared:\n",
    "```sh\n",
    "julia\n",
    "import Pkg\n",
    "Pkg.update()\n",
    "Pkg.precompile()\n",
    "\n",
    "using Pkg\n",
    "Pkg.build(\"IJulia\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "using HDF5\n",
    "using Serialization\n",
    "using DataFrames, Plots, Statistics\n",
    "using Plots.PlotMeasures \n",
    "using DataFramesMeta\n",
    "using Missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "safe_max (generic function with 1 method)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_data(v) = any(!ismissing, v)\n",
    "safe_mean(v) = has_data(v) ? mean(skipmissing(v)) : missing\n",
    "# safe_std(v) = has_data(v) ? max(0, std(collect(skipmissing(v)); corrected=false)) : missing\n",
    "function safe_std(v)\n",
    "    if has_data(v)\n",
    "        result = std(collect(skipmissing(v)); corrected=false)\n",
    "        if result < 0\n",
    "            println(\"Warning: negative std encountered, setting to 0.0\")\n",
    "            result = 0.0\n",
    "        end\n",
    "        return abs(result)\n",
    "    else\n",
    "        return missing\n",
    "    end\n",
    "end\n",
    "safe_min(v)  = has_data(v) ? minimum(skipmissing(v)) : missing\n",
    "safe_max(v)  = has_data(v) ? maximum(skipmissing(v)) : missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rename_regime (generic function with 1 method)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rename_regime(trial)\n",
    "    if trial == \"1(1.0) particles\"\n",
    "        return \"Extreme degeneracy\"\n",
    "    elseif trial == \"1(0.999) particles\"\n",
    "        return \"High degeneracy\"\n",
    "    elseif trial == \"1(0.99) particles\"\n",
    "        return \"Near-degeneracy(0.99)\"\n",
    "    elseif trial == \"50%(1.0) particles\"\n",
    "        return \"Balanced regime\"\n",
    "    elseif trial == \"all(1.0) particles\"\n",
    "        return \"Uniform regime\"\n",
    "    end\n",
    "    return trial\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timer_dict_to_df (generic function with 3 methods)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function timer_dict_to_df(timer_dict, optimization, flatten=false)\n",
    "    rows = []\n",
    "\n",
    "    for (trial, ranks) in timer_dict\n",
    "        k, total_rank, nprt_per_rank, n_float_per_particle, perm, p = split(trial, \":\")\n",
    "        k = k == \"half\" ? \"50%\" : k\n",
    "        trial_name = \"$k($p) particles\"\n",
    "        for (rank, timers) in ranks\n",
    "            function format_row(op, metric, value)\n",
    "                return (\n",
    "                    optimization = optimization,\n",
    "                    trial  = String(trial_name),\n",
    "                    perm = String(perm),\n",
    "                    total_rank = parse(Int, total_rank),\n",
    "                    particle_size = n_float_per_particle,\n",
    "                    nprt_per_rank = nprt_per_rank,\n",
    "                    rank   = string(rank),\n",
    "                    op     = String(op),\n",
    "                    metric = String(metric),\n",
    "                    value  = value,\n",
    "                )\n",
    "            end\n",
    "            function recursive_push(inner_timers)\n",
    "                for (op, metrics) in inner_timers\n",
    "                    if op == \"receive loop\" && flatten\n",
    "                        for (inner_op, inner_metrics) in metrics[\"inner_timers\"]\n",
    "                            for (metric, value) in inner_metrics\n",
    "                                push!(rows, format_row(inner_op, metric, value))\n",
    "                            end\n",
    "                        end\n",
    "                    else\n",
    "                        push!(rows, format_row(op, \"time_s\", metrics[\"time_ns\"] / 1e9))\n",
    "                        push!(rows, format_row(op, \"n_calls\", metrics[\"n_calls\"]))\n",
    "                        recursive_push(metrics[\"inner_timers\"])\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            push!(rows, format_row(\"overall\", \"time_s\", timers[\"time_ns\"] / 1e9))\n",
    "            push!(rows, format_row(\"overall\", \"n_calls\", timers[\"n_calls\"]))\n",
    "            recursive_push(timers[\"inner_timers\"])\n",
    "        end\n",
    "    end\n",
    "    return DataFrame(rows)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function render(df, label=false)\n",
    "#   trials = unique(df.trial)\n",
    "#   ops    = unique(df.op)\n",
    "\n",
    "#   ntrials, nops = length(trials), length(ops)\n",
    "\n",
    "#   # 2) Create an empty grid, with row & column titles\n",
    "#   plt = plot(\n",
    "#     layout     = (ntrials, nops),\n",
    "#     legend = label ? :topleft : :none,\n",
    "#     size       = (300 * nops, 300 * ntrials),\n",
    "#   )\n",
    "\n",
    "#   # 3) Fill it in\n",
    "#   for (i, trial) in enumerate(trials)\n",
    "#     for (j, op) in enumerate(ops)\n",
    "#       sub = df[(df.trial .== trial) .& (df.op .== op), :]\n",
    "#       for rk in unique(sub.rank)\n",
    "#         subrk = sub[sub.rank .== rk, :]\n",
    "#         scatter!(\n",
    "#           plt[i, j],\n",
    "#           string.(subrk.total_rank),    # categorical x\n",
    "#           subrk.time_ms;\n",
    "#           marker     = :circle,\n",
    "#           markersize = 4,\n",
    "#           label      = rk,\n",
    "#           right_margin = 10mm,\n",
    "#           color      = rk == \"0\" ? :blue : :orange,\n",
    "#         )\n",
    "#       end\n",
    "#       plot!(plt[i, j], title = string(op), top_margin = 10mm)\n",
    "#       if j == 1\n",
    "#         plot!(plt[i, j], ylabel = string(trial), left_margin = 20mm)\n",
    "#       end\n",
    "\n",
    "#       # only the bottom row gets the shared xâ€axis label\n",
    "#       if i == ntrials\n",
    "#         plot!(plt[i, j], xlabel = \"Total Rank\")\n",
    "#       end\n",
    "#     end\n",
    "#   end\n",
    "\n",
    "#   display(plt)\n",
    "#   return plt\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_from_h5 (generic function with 1 method)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function df_from_h5(root_dir, category)\n",
    "    optimization = split(category, \"/\")[end]\n",
    "\n",
    "    root = dirname(@__FILE__)\n",
    "    h5path(rank) = joinpath(root, \"../$(root_dir)/$(category)/\", \"all_timers_$(rank).h5\") \n",
    "    all_timer_dfs = DataFrame()\n",
    "    for rank in [2, 4, 8, 16, 32]\n",
    "        blob = h5open(h5path(rank)) do f\n",
    "            read(f, \"all_timers\")\n",
    "        end\n",
    "\n",
    "        # Deserialize back into Dict{String,Dict{Int,Dict{String,Any}}}\n",
    "        merged_timers = deserialize(IOBuffer(blob))\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        timer_df = timer_dict_to_df(merged_timers, optimization)\n",
    "        \n",
    "        # Concat to all_timer_dfs\n",
    "        all_timer_dfs = vcat(all_timer_dfs, timer_df)\n",
    "    end\n",
    "\n",
    "    wide = unstack(\n",
    "    all_timer_dfs,\n",
    "    [:optimization, :trial, :perm, :total_rank, :nprt_per_rank, :particle_size, :rank, :op],\n",
    "    :metric,\n",
    "    :value\n",
    "    )\n",
    "    # Sort by perm and trial\n",
    "    wide = sort!(wide, [:perm, :trial])\n",
    "\n",
    "    first_df = wide[wide.perm .== \"firstperm\", :]\n",
    "    rand_df = wide[wide.perm .== \"randperm\", :]\n",
    "    return (first_df, rand_df)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "widen_ops (generic function with 1 method)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function widen_ops(df::DataFrame)\n",
    "    rename!(df, Symbol.(names(df)))\n",
    "\n",
    "    keys   = [:optimization, :trial, :perm, :total_rank, :nprt_per_rank, :particle_size, :rank]\n",
    "    wanted = [\"overall\",\"waitall\",\"broadcast\",\"copy states\",\"write from buffer\",\"write to buffer\", \"waitall phase\", \"buffer write-back\",\n",
    "              \"receive loop\",\"send loop\",\"irecv\",\"remote duplicates copy\", \"optimize resample\", \"local copy\", \"remote receive\", \"send plan\", \"receive plan\", \"local replication\", \"local replication\", \"remote replication\"]\n",
    "\n",
    "    df2 = subset(df, :op => ByRow(in(wanted)))\n",
    "\n",
    "    transform!(df2, :n_calls => ByRow(x -> x == 0 ? missing : x) => :n_calls)\n",
    "\n",
    "    g = groupby(df2, vcat(keys, [:op]))\n",
    "    avg = combine(g,\n",
    "        [:time_s, :n_calls] => ((t, c) -> sum(t) / sum(c) ) => :time_s_per_call\n",
    "    )\n",
    "\n",
    "    wide = unstack(avg, keys, :op, :time_s_per_call; combine=first)\n",
    "    rename!(wide, Symbol.(replace.(string.(names(wide)), r\"[ -]\" => \"_\")))\n",
    "    return wide\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stats (generic function with 1 method)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function stats(df_stats)\n",
    "    df_stats = @chain df_stats[df_stats.total_rank .> 1, :] begin\n",
    "        @transform(\n",
    "            :waitall_ratio = :waitall_phase ./ :overall,\n",
    "            :localcopy_ratio = :local_replication ./ :overall,\n",
    "            :remotedup_ratio = :remote_replication ./ :overall,\n",
    "            :writefrombuf_ratio = :buffer_write_back ./ :overall,\n",
    "            :resample_ratio = :optimize_resample ./ :overall,\n",
    "            # :overall_time_log = log2.(:overall),\n",
    "            # :waitall_time_log = log2.(:waitall_phase),\n",
    "            # :copy_states_time_log = log2.(:copy_states),\n",
    "            # :resample_time_log = log2.(:optimize_resample)\n",
    "        )\n",
    "    end\n",
    "    return df_stats\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rename_optimization (generic function with 1 method)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rename_stats(metric)\n",
    "    if metric == \"waitall_ratio\"\n",
    "        return \"Waitall/Overall Time Ratio\"\n",
    "    elseif metric == \"overall\"\n",
    "        return \"Overall Time (s)\"\n",
    "    elseif metric == \"copy_states\"\n",
    "        return \"Copy States Time (s)\"\n",
    "    elseif metric == \"waitall_phase\"\n",
    "        return \"Waitall Time (s)\"\n",
    "    elseif metric == \"optimize_resample\"\n",
    "        return \"Optimise Resample (s)\"\n",
    "    elseif metric == \"resample_ratio\"\n",
    "        return \"Overhead Time Ratio\"\n",
    "    else\n",
    "        return metric\n",
    "    end\n",
    "end\n",
    "\n",
    "function rename_optimization(optimization)\n",
    "    if optimization == \"original\"\n",
    "        return \"Baseline\"\n",
    "    elseif optimization == \"only_optimize_resampling\"\n",
    "        return \"Optimise Resampling Only\"\n",
    "    elseif optimization == \"only_dedup\"\n",
    "        return \"Deduplication Only\"\n",
    "    elseif optimization == \"dedup_threading\"\n",
    "        return \"Deduplication + Threading\"\n",
    "    elseif optimization == \"dedup_threading_optimize_resampling\"\n",
    "        return \"Full Optimisation\"\n",
    "    else\n",
    "        return optimization\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "render_stats (generic function with 3 methods)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function render_stats(df, stats_to_plot=[\"overall\", \"copy_states\", \"waitall_phase\", \"waitall_ratio\"])\n",
    "    # Configuration for plots\n",
    "    trials = [\"1(1.0) particles\", \"1(0.99) particles\", \"50%(1.0) particles\", \"all(1.0) particles\"]\n",
    "    optimizations = unique(df.optimization)\n",
    "    ntrials = length(trials)\n",
    "    nstats = length(stats_to_plot)\n",
    "    n_opts = length(optimizations)\n",
    "\n",
    "    # --- Create the individual plots for the grid ---\n",
    "    axes = []\n",
    "    for (i, trial) in enumerate(trials)\n",
    "        for (j, stat) in enumerate(stats_to_plot)\n",
    "            # Create a new plot object for this subplot\n",
    "            p = plot(legend=false, palette=:auto, bottom_margin=10mm)\n",
    "            \n",
    "            # --- Set conditional labels and titles ---\n",
    "            if i == 1\n",
    "                plot!(p, title = rename_stats(stat), top_margin = 10mm)\n",
    "            end\n",
    "            if j == 1\n",
    "                plot!(p, ylabel = rename_regime(trial), left_margin = 20mm)\n",
    "            end\n",
    "            if i == ntrials\n",
    "                plot!(p, xlabel = \"Total Rank\", bottom_margin = 10mm)\n",
    "            end\n",
    "\n",
    "            df_filtered = df[df.trial .== trial, :]\n",
    "            \n",
    "            # --- Add each optimization as a series to the plot ---\n",
    "            for optimization in optimizations\n",
    "                sub = select(df_filtered, :optimization, :total_rank, :rank, stat => :value)\n",
    "                subrk = sub[sub.optimization .== optimization, :]\n",
    "                isempty(subrk) && continue\n",
    "\n",
    "                # Determine if log scale should be used\n",
    "                use_log = stat in [\"overall\", \"copy_states\", \"waitall_phase\"]\n",
    "\n",
    "                # Group and calculate statistics.\n",
    "                g = if use_log\n",
    "                    # Add a small epsilon to avoid log(0) issues\n",
    "                    subrk_log = @transform(subrk, :log_value = log10.(:value .+ 1e-12))\n",
    "                    \n",
    "                    # Calculate stats in both linear (for mean) and log (for std) space\n",
    "                    g_linear = combine(groupby(subrk, :total_rank), :value => safe_mean => :mean)\n",
    "                    g_log = combine(groupby(subrk_log, :total_rank), :log_value => safe_std  => :std_log)\n",
    "                    \n",
    "                    # Join them together and return\n",
    "                    leftjoin(g_linear, g_log, on = :total_rank)\n",
    "                else\n",
    "                    combine(groupby(subrk, :total_rank),\n",
    "                            :value => safe_mean => :mean,\n",
    "                            :value => safe_std  => :std)\n",
    "                end\n",
    "\n",
    "                # Filter out rows with missing data and sort\n",
    "                filter!(row -> all(!ismissing, values(row)), g)\n",
    "                sort!(g, :total_rank)\n",
    "                isempty(g) && continue\n",
    "                \n",
    "                # Prepare plot variables (mean and ribbon) based on the scale\n",
    "                local plot_mean, ribbon_val\n",
    "                if use_log\n",
    "                    plot!(p, yaxis=:log)\n",
    "                    # Use the arithmetic mean for the central line\n",
    "                    plot_mean = g.mean\n",
    "                    \n",
    "                    # Calculate the geometric standard deviation as a multiplicative factor\n",
    "                    gstd = 10 .^ g.std_log\n",
    "                    \n",
    "                    # Define ribbon bounds multiplicatively around the arithmetic mean\n",
    "                    lower_bound = plot_mean ./ gstd\n",
    "                    upper_bound = plot_mean .* gstd\n",
    "                    \n",
    "                    # The ribbon is the distance from the central line\n",
    "                    ribbon_val = (plot_mean .- lower_bound, upper_bound .- plot_mean)\n",
    "                else\n",
    "                    plot_mean = g.mean\n",
    "                    ribbon_val = g.std\n",
    "                end\n",
    "\n",
    "                plot!(p, string.(g.total_rank), plot_mean,\n",
    "                      ribbon = ribbon_val, seriestype = :path,\n",
    "                      markersize = 4, linewidth = 1.5)\n",
    "            end\n",
    "            push!(axes, p)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # --- Create the global legend ---\n",
    "    legend_labels = permutedims([rename_optimization(opt) for opt in optimizations])\n",
    "    legend_plot = plot(\n",
    "        (1:n_opts)', # Dummy data for legend entries\n",
    "        legend = :top,\n",
    "        legend_columns = -1, # Force a single horizontal row\n",
    "        labels = legend_labels,\n",
    "        framestyle = :none,\n",
    "        palette = :auto,\n",
    "        size = (1,1)\n",
    "    )\n",
    "\n",
    "    # --- Combine legend and plots into the final figure ---\n",
    "    final_fig = plot(\n",
    "        legend_plot,\n",
    "        axes...,\n",
    "        layout = @layout([A{0.05h}; grid(ntrials, nstats)]),\n",
    "        size = (400 * nstats, 300 * ntrials)\n",
    "    )\n",
    "\n",
    "    return final_fig\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "render_overhead (generic function with 3 methods)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function render_overhead(df, stats_to_plot=[\"optimize_resample\", \"resample_ratio\"])\n",
    "    # Configuration for plots\n",
    "    trials = [\"1(1.0) particles\", \"1(0.99) particles\", \"50%(1.0) particles\", \"all(1.0) particles\"]\n",
    "    nstats = length(stats_to_plot)\n",
    "    ntrials = length(trials)\n",
    "\n",
    "    # --- Create the individual plots for the row ---\n",
    "    axes = []\n",
    "    # Filter the DataFrame for the single optimization we care about\n",
    "    df_opt_filtered = df\n",
    "    \n",
    "    for (j, stat) in enumerate(stats_to_plot)\n",
    "        # Create a new plot object for this subplot\n",
    "        p = plot(legend=false, palette=:auto, bottom_margin=10mm, title=rename_stats(stat), top_margin=10mm)\n",
    "        \n",
    "        # Add common labels\n",
    "        plot!(p, xlabel = \"Total Rank\")\n",
    "        # if j == 1\n",
    "        #     plot!(p, ylabel = \"Value\", left_margin=20mm)\n",
    "        # end\n",
    "\n",
    "        # --- Add each trial as a series to the plot ---\n",
    "        for trial in trials\n",
    "            sub = select(df_opt_filtered[df_opt_filtered.trial .== trial, :], :total_rank, :rank, stat => :value)\n",
    "            isempty(sub) && continue\n",
    "\n",
    "            # Determine if log scale should be used based on the stat name\n",
    "            use_log = stat in []\n",
    "\n",
    "            # Group and calculate statistics\n",
    "            g = if use_log\n",
    "                sub_log = @transform(sub, :log_value = log10.(:value .+ 1e-12))\n",
    "                g_linear = combine(groupby(sub, :total_rank), :value => safe_mean => :mean)\n",
    "                g_log = combine(groupby(sub_log, :total_rank), :log_value => safe_std  => :std_log)\n",
    "                leftjoin(g_linear, g_log, on = :total_rank)\n",
    "            else\n",
    "                combine(groupby(sub, :total_rank),\n",
    "                        :value => safe_mean => :mean,\n",
    "                        :value => safe_std  => :std)\n",
    "            end\n",
    "\n",
    "            filter!(row -> all(!ismissing, values(row)), g)\n",
    "            sort!(g, :total_rank)\n",
    "            isempty(g) && continue\n",
    "            \n",
    "            # Prepare plot variables\n",
    "            local plot_mean, ribbon_val\n",
    "            if use_log\n",
    "                plot!(p, yaxis=:log)\n",
    "                plot_mean = g.mean\n",
    "                gstd = 10 .^ g.std_log\n",
    "                lower_bound = plot_mean ./ gstd\n",
    "                upper_bound = plot_mean .* gstd\n",
    "                ribbon_val = (plot_mean .- lower_bound, upper_bound .- plot_mean)\n",
    "            else\n",
    "                plot_mean = g.mean\n",
    "                ribbon_val = g.std\n",
    "            end\n",
    "\n",
    "            plot!(p, string.(g.total_rank), plot_mean,\n",
    "                  ribbon = ribbon_val, seriestype = :path,\n",
    "                  markersize = 4, linewidth = 1.5)\n",
    "        end\n",
    "        push!(axes, p)\n",
    "    end\n",
    "\n",
    "    # --- Create the global legend for trials ---\n",
    "    legend_labels = permutedims([rename_regime(t) for t in trials])\n",
    "    legend_plot = plot(\n",
    "        (1:ntrials)',\n",
    "        legend = :top,\n",
    "        legend_columns = -1,\n",
    "        labels = legend_labels,\n",
    "        framestyle = :none,\n",
    "        palette = :auto,\n",
    "        size = (1,1)\n",
    "    )\n",
    "\n",
    "    # --- Combine legend and plots ---\n",
    "    final_fig = plot(\n",
    "        legend_plot,\n",
    "        axes...,\n",
    "        layout = @layout([A{0.1h}; grid(1, nstats)]),\n",
    "        size = (450 * nstats, 400)\n",
    "    )\n",
    "\n",
    "    return final_fig\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/UCL/masterproj/ParticleDA.jl/extra/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/UCL/masterproj/ParticleDA.jl/extra/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; Pkg.add(\"ColorSchemes\")\n",
    "using ColorSchemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = \"test/output29\"\n",
    "# _, original_100k_df = df_from_h5(root_dir, \"original\")\n",
    "# function stats(df_stats)\n",
    "#     df_copy_states = df_stats[df_stats.op .== \"copy states\", :]\n",
    "#     rename!(df_copy_states, :time_s => :copy_states_time_s)\n",
    "#     df_stats = df_stats[(df_stats.op .!= \"overall\") .& (df_stats.op .!= \"broadcast\"), :]\n",
    "#     df_stats = leftjoin(df_stats, df_copy_states, on=[:optimization, :trial, :total_rank, :rank], makeunique=true)\n",
    "#     df_stats = @chain df_stats[df_stats.total_rank .> 1, :] begin\n",
    "#         @transform(\n",
    "#             :time_ratio = :time_s ./ :copy_states_time_s\n",
    "#         )\n",
    "#     end\n",
    "#     return df_stats\n",
    "# end\n",
    "# original_100k_df = stats(original_100k_df)\n",
    "\n",
    "# function render_stats_refactored(df)\n",
    "#     # Configuration for plots\n",
    "#     trials = [\"1(1.0) particles\", \"1(0.99) particles\",\n",
    "#               \"50%(1.0) particles\", \"all(1.0) particles\"]\n",
    "#     stats_metrics = [\"copy states\", \"waitall phase\", \"buffer write-back\",\n",
    "#                      \"receive loop\",\"send loop\",\"send plan\", \"receive plan\", \"local replication\", \"remote replication\"]\n",
    "#     # filter out metrics not present in the DataFrame\n",
    "#     stats_metrics = filter(metric -> any(df.op .== metric), stats_metrics)\n",
    "#     nstats = length(stats_metrics)\n",
    "\n",
    "#     # Helper to rename metrics for the legend\n",
    "#     function rename_stats(op)\n",
    "#         if op == \"waitall\"\n",
    "#             return \"waitall phase\"\n",
    "#         elseif op == \"write from buffer\"\n",
    "#             return \"buffer write-back\"\n",
    "#         end\n",
    "#         return op\n",
    "#     end\n",
    "    \n",
    "#     # Get a consistent color palette for all series\n",
    "#     colors = get_color_palette(ColorSchemes.Set1_9, plot_color(:white))[1:nstats]\n",
    "    \n",
    "#     # 1. Create each of the four subplots individually\n",
    "#     axes = []\n",
    "#     for (i, trial) in enumerate(trials)\n",
    "#         # Create a blank plot for the current trial\n",
    "#         p = plot(\n",
    "#             title = rename_regime(trial), \n",
    "#             xlabel = \"Total Rank\",\n",
    "#             bottom_margin = 10mm,\n",
    "#         )\n",
    "        \n",
    "#         # Add Y-axis label only to the plots in the first column\n",
    "#         if i in [1, 3]\n",
    "#             plot!(p, ylabel = \"Time Breakdown\", left_margin = 15mm)\n",
    "#         end\n",
    "\n",
    "#         df_filtered = df[df.trial .== trial, :]\n",
    "\n",
    "#         # Add each metric as a series to the plot\n",
    "#         for (j, metric) in enumerate(stats_metrics)\n",
    "#             subrk = df_filtered[df_filtered.op .== metric, :]\n",
    "            \n",
    "#             # Skip if there's no data for this metric\n",
    "#             isempty(subrk) && continue\n",
    "\n",
    "#             g = combine(groupby(subrk, :total_rank),\n",
    "#                         :time_ratio => safe_mean => :mean,\n",
    "#                         :time_ratio => safe_std  => :std)\n",
    "#             filter!(row -> !ismissing(row.mean) && !ismissing(row.std), g)\n",
    "#             sort!(g, :total_rank)\n",
    "\n",
    "#             isempty(g) && continue\n",
    "\n",
    "#             plot!(\n",
    "#                 p,\n",
    "#                 string.(g.total_rank),\n",
    "#                 g.mean,\n",
    "#                 ribbon = g.std,\n",
    "#                 seriestype = :path,\n",
    "#                 markersize = 4,\n",
    "#                 linewidth = 1.5,\n",
    "#                 label = \"\", # Disable individual labels\n",
    "#                 color = colors[j]\n",
    "#             )\n",
    "#         end\n",
    "#         push!(axes, p)\n",
    "#     end\n",
    "\n",
    "#     # 2. Create a separate plot object that only contains the legend\n",
    "#     legend_labels = permutedims([rename_stats(s) for s in stats_metrics])\n",
    "#     legend_plot = plot(\n",
    "#         (1:nstats)', \n",
    "#         legend_position = :outertop, \n",
    "#         legend_columns = 3, \n",
    "#         labels = legend_labels, \n",
    "#         colors = colors, \n",
    "#         framestyle = :none,\n",
    "#         palette = colors,\n",
    "#     )\n",
    "\n",
    "#     # 3. Combine the legend and the subplots into a final figure\n",
    "#     # The layout places the legend ('l') in a small top row,\n",
    "#     # followed by a 2x2 grid of the other plots.\n",
    "#     final_fig = plot(\n",
    "#         legend_plot,\n",
    "#         axes...,\n",
    "#         layout = @layout([l{0.1h}; grid(2, 2)]),\n",
    "#         size = (900, 750)\n",
    "#     )\n",
    "\n",
    "#     return final_fig\n",
    "# end\n",
    "# render_stats_refactored(original_100k_df)\n",
    "# savefig(\"copy_states_original_time_breakdown.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/sunchenge/Desktop/UCL/masterproj/ParticleDA.jl/extra/overhead.pdf\""
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = \"test/output29\"\n",
    "_, original_100k_df = df_from_h5(root_dir, \"original\")\n",
    "_, dedup_100k_df = df_from_h5(root_dir, \"only_dedup\")\n",
    "_, dedup_threads_100k_df = df_from_h5(root_dir, \"dedup_threading\")\n",
    "# _, op_100k_df = df_from_h5(root_dir, \"only_optimize_resampling\")\n",
    "_, dtop_100k_df = df_from_h5(root_dir, \"dedup_threading_optimize_resampling\")\n",
    "\n",
    "union_df = vcat(original_100k_df, dedup_100k_df, dedup_threads_100k_df, dtop_100k_df)\n",
    "union_df = widen_ops(union_df)\n",
    "union_df = stats(union_df)\n",
    "println(\"Data loaded and processed.\")\n",
    "\n",
    "# stats\n",
    "# stats_df = combine(groupby(union_df, [:optimization, :trial, :total_rank]), :overall => mean => :overall_mean)\n",
    "# original_stats = stats_df[stats_df.optimization .== \"original\", [:trial, :total_rank, :overall_mean]]\n",
    "# rename!(original_stats, :overall_mean => :original_overall_mean)\n",
    "# stats_df = leftjoin(stats_df, original_stats, on=[:trial, :total_rank])\n",
    "# stats_df = @chain stats_df begin\n",
    "#     @transform(\n",
    "#         improvement = (:original_overall_mean .- :overall_mean) ./ :original_overall_mean * 100\n",
    "#     )\n",
    "#     sort!([:trial, :total_rank, :optimization])\n",
    "# end\n",
    "# stats_df = stats_df[stats_df.optimization .== \"dedup_threading_optimize_resampling\", :]\n",
    "# render_stats(union_df)\n",
    "# render_overhead(union_df, [\"optimize_resample\", \"resample_ratio\"])\n",
    "\n",
    "# println(union_df[union_df.total_rank .== 32 .&& union_df.optimization .== \"original\", :])\n",
    "savefig(\"overhead.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function timer_dict_to_df(timer_dict, optimization, total_rank, flatten=false)\n",
    "#     rows = []\n",
    "\n",
    "#         for (rank, timers) in timer_dict\n",
    "#             function format_row(op, metric, value)\n",
    "#                 return (\n",
    "#                     optimization = optimization,\n",
    "#                     total_rank = total_rank,\n",
    "#                     rank   = string(rank),\n",
    "#                     op     = String(op),\n",
    "#                     metric = String(metric),\n",
    "#                     value  = value,\n",
    "#                 )\n",
    "#             end\n",
    "#             function recursive_push(inner_timers)\n",
    "#                 for (op, metrics) in inner_timers\n",
    "#                     if op == \"receive loop\" && flatten\n",
    "#                         for (inner_op, inner_metrics) in metrics[\"inner_timers\"]\n",
    "#                             for (metric, value) in inner_metrics\n",
    "#                                 push!(rows, format_row(inner_op, metric, value))\n",
    "#                             end\n",
    "#                         end\n",
    "#                     else\n",
    "#                         push!(rows, format_row(op, \"time_s\", metrics[\"time_ns\"] / 1e9))\n",
    "#                         push!(rows, format_row(op, \"n_calls\", metrics[\"n_calls\"]))\n",
    "#                         recursive_push(metrics[\"inner_timers\"])\n",
    "#                     end\n",
    "#                 end\n",
    "#             end\n",
    "#             push!(rows, format_row(\"End-to-End\", \"time_s\", timers[\"total_time_ns\"] / 1e9))\n",
    "#             push!(rows, format_row(\"End-to-End\", \"n_calls\", 1))\n",
    "#             recursive_push(timers[\"inner_timers\"])\n",
    "#         end\n",
    "#     return DataFrame(rows)\n",
    "# end\n",
    "\n",
    "# function df_from_h5(root_dir, category)\n",
    "#     optimization = split(category, \"/\")[end]\n",
    "\n",
    "#     root = dirname(@__FILE__)\n",
    "#     h5path(rank) = joinpath(root, \"../$(root_dir)/$(category)/\", \"all_timers_$(rank).h5\") \n",
    "#     all_timer_dfs = DataFrame()\n",
    "#     for rank in [2, 4, 8, 16]\n",
    "#         blob = h5open(h5path(rank)) do f\n",
    "#             read(f, \"all_timers\")\n",
    "#         end\n",
    "\n",
    "#         # Deserialize back into Dict{String,Dict{Int,Dict{String,Any}}}\n",
    "#         merged_timers = deserialize(IOBuffer(blob))\n",
    "#         # println(merged_timers)\n",
    "\n",
    "#         timer_df = timer_dict_to_df(merged_timers, optimization, rank)\n",
    "\n",
    "#         all_timer_dfs = vcat(all_timer_dfs, timer_df)\n",
    "#     end\n",
    "#     return all_timer_dfs\n",
    "# end\n",
    "# original = df_from_h5(\"test/overall\", \"original\")\n",
    "# optimized = df_from_h5(\"test/overall\", \"optimized\")\n",
    "# union_df = vcat(original, optimized)\n",
    "# union_df = union_df[union_df.op .== \"End-to-End\" .|| union_df.op .== \"Copy states\", :]\n",
    "# union_df = union_df[union_df.metric .== \"time_s\", :]\n",
    "# stats_df = combine(groupby(union_df, [:optimization, :total_rank, :op, :metric]), :value => safe_mean => :mean, :value => safe_std => :std)\n",
    "# original_stats_df = stats_df[stats_df.optimization .== \"original\", [:total_rank, :op, :metric, :mean]]\n",
    "# rename!(original_stats_df, :mean => :original_mean)\n",
    "# stats_df = leftjoin(stats_df, original_stats_df, on=[:total_rank, :op, :metric])\n",
    "# stats_df = @chain stats_df begin\n",
    "#     @transform(\n",
    "#         improvement = (:original_mean .- :mean) ./ :original_mean * 100\n",
    "#     )\n",
    "#     sort!([:total_rank, :optimization, :op])\n",
    "# end \n",
    "# stats_df = stats_df[stats_df.optimization .== \"optimized\", :]\n",
    "# println(stats_df)\n",
    "# function render_stats_refactored(df)\n",
    "#     # Configuration for plots\n",
    "#     stats_to_plot = [\"End-to-End\", \"Copy states\"]\n",
    "#     optimizations = unique(df.optimization)\n",
    "#     n_opts = length(optimizations)\n",
    "\n",
    "#     # --- Create the individual plots for the grid ---\n",
    "#     axes = []\n",
    "#     for (i, stat) in enumerate(stats_to_plot)\n",
    "#         # Create a new plot object for this subplot\n",
    "#         p = plot(\n",
    "#             title = stat * \" Time (s)\",\n",
    "#             xlabel = \"Total Rank\",\n",
    "#             yaxis = :log, # Use a logarithmic scale for the y-axis\n",
    "#             legend = false, # Disable individual legends\n",
    "#             palette = :auto,\n",
    "#             bottom_margin = 10mm\n",
    "#         )\n",
    "        \n",
    "#         # Add Y-axis label only to the first plot\n",
    "#         if i == 1\n",
    "#             plot!(p, ylabel = \"Time (log scale)\", left_margin = 15mm)\n",
    "#         end\n",
    "\n",
    "#         df_filtered = df[(df.op .== stat) .& (df.metric .== \"time_s\"), :]\n",
    "\n",
    "#         # Add each optimization as a series to the plot\n",
    "#         for optimization in optimizations\n",
    "#             subrk = df_filtered[df_filtered.optimization .== optimization, :]\n",
    "#             isempty(subrk) && continue\n",
    "\n",
    "#             g = combine(groupby(subrk, :total_rank),\n",
    "#                         :value => safe_mean => :mean,\n",
    "#                         :value => safe_std  => :std)\n",
    "#             filter!(row -> !ismissing(row.mean) && !ismissing(row.std), g)\n",
    "#             sort!(g, :total_rank)\n",
    "#             isempty(g) && continue\n",
    "\n",
    "#             plot!(p, string.(g.total_rank), g.mean,\n",
    "#                   ribbon = g.std, seriestype = :path,\n",
    "#                   markersize = 4, linewidth = 1.5)\n",
    "#         end\n",
    "#         push!(axes, p)\n",
    "#     end\n",
    "\n",
    "#     # --- Create the global legend ---\n",
    "#     legend_labels = permutedims(optimizations)\n",
    "#     legend_plot = plot(\n",
    "#         (1:n_opts)', # Dummy data to generate legend entries\n",
    "#         legend = :top,\n",
    "#         legend_columns = -1, # Forces a single horizontal row\n",
    "#         labels = legend_labels,\n",
    "#         framestyle = :none,\n",
    "#         palette = :auto,\n",
    "#         size = (1,1) # Minimal size, as it's just for the legend\n",
    "#     )\n",
    "\n",
    "#     # --- Combine legend and plots into the final figure ---\n",
    "#     final_fig = plot(\n",
    "#         legend_plot,\n",
    "#         axes...,\n",
    "#         layout = @layout([A{0.1h}; grid(1, 2)]), # 1x2 grid for the two stats\n",
    "#         size = (800, 500) # Adjusted size for the 1x2 layout\n",
    "#     )\n",
    "\n",
    "#     return final_fig\n",
    "# end\n",
    "# # render_stats_refactored(union_df)\n",
    "# # savefig(\"real_model.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
